{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f07d33da",
   "metadata": {},
   "source": [
    "## Финальный pipeline модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "915ae810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif, chi2, mutual_info_classif, SelectFromModel\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.metrics import r2_score, mean_squared_error as MSE, mean_absolute_percentage_error as MAPE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, mutual_info_regression, f_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed8f7135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# данные предобрабатываются из БД\n",
    "df = pd.read_csv('../data/expanded_data_with_OSM.csv', sep = ',')\n",
    "df_target = pd.read_csv('../data/train.csv', sep = ',')\n",
    "\n",
    "regions_data = pd.read_csv('../data/regions_data.csv', sep = ';').rename(columns={'Unnamed: 0': 'regions'})\n",
    "df = df.merge(regions_data, how='left', on='regions')\n",
    "\n",
    "df = df.merge(df_target[['id', 'target']], how='left', on='id')\n",
    "\n",
    "dff = pd.DataFrame(df.isna().sum()/len(df)).reset_index()\n",
    "dff = dff[dff[0] > 0]\n",
    "\n",
    "for col in dff[dff[0] > 0]['index']:\n",
    "    if col != 'regions':\n",
    "        df[col] = df[col].fillna(df[col].max())\n",
    "\n",
    "df['regions'].replace(np.nan, 'Southern Federal District', inplace=True)\n",
    "\n",
    "df = df[df['test_train_flag'] == 'train']\n",
    "df['capital'] = np.where((df['cities'] == 'Moscow') | (df['cities'] == 'Saint Petersburg'), 1, 0)\n",
    "\n",
    "df = df.merge(df.groupby('cities').agg({'target': 'mean'}).reset_index().rename(columns={'target': 'avgC'}),\n",
    "         how='left', on='cities')\n",
    "\n",
    "df = df.merge(df.groupby('regions').agg({'target': 'mean'}).reset_index().rename(columns={'target': 'avgR'}),\n",
    "         how='left', on='regions')\n",
    "\n",
    "df = df.merge(df.groupby('states').agg({'target': 'mean'}).reset_index().rename(columns={'target': 'avgS'}),\n",
    "         how='left', on='states')\n",
    "\n",
    "df = df.merge(df.groupby('atm_group').agg({'target': 'mean'}).reset_index().rename(columns={'target': 'avgA'}),\n",
    "         how='left', on='atm_group')\n",
    "\n",
    "\n",
    "df['atm_group'] = df['atm_group'].astype(int)\n",
    "\n",
    "y = df['target'].reset_index(drop=True)\n",
    "X = df.loc[:, ~df.columns.isin(['target', 'id', 'address', 'address_rus', 'lat', 'lng',\n",
    "                                'test_train_flag', 'geometry'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12fbebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea1eafe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: R2: 0.7840559103741536, MSE: 0.0016100389298148434, RMSE: 0.040125290401626296\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "# !!!!!!!!!!!\n",
    "# pca = PCA(n_components=50)\n",
    "pca = SelectKBest(score_func=f_regression, k=100)\n",
    "\n",
    "# get the categorical and numeric column names\n",
    "num_cols = X_train.select_dtypes(exclude=['object']).columns.tolist()\n",
    "cat_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# pipeline for numerical columns\n",
    "num_pipe = make_pipeline(\n",
    "#     SimpleImputer(strategy='mean'),\n",
    "    StandardScaler()\n",
    ")\n",
    "# pipeline for categorical columns\n",
    "cat_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    ")\n",
    "\n",
    "# combine both the pipelines\n",
    "full_pipe = ColumnTransformer([\n",
    "    ('num', num_pipe, num_cols),\n",
    "    ('cat', cat_pipe, cat_cols)\n",
    "])\n",
    "\n",
    "# build the model\n",
    "rff = Pipeline([\n",
    "    ('coltrans', full_pipe),\n",
    "    ('pca', pca),\n",
    "    ('model', RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# train the model\n",
    "rff.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = rff.predict(X_test)\n",
    "\n",
    "# measure quality\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "rmse_test = MSE(y_test, y_pred, squared=False)\n",
    "# mape_test = MAPE(y_test, y_pred)\n",
    "\n",
    "# print(f\"TRAIN: R2: {r2_train}, MSE: {cb_mse_train}, \\\n",
    "# RMSE: {cb_rmse_train}\\n\")\n",
    "print(f\"TEST: R2: {r2_test}, MSE: {mse_test}, \\\n",
    "RMSE: {rmse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cddde46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>num__avgA</td>\n",
       "      <td>3.372994e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num__atm_group</td>\n",
       "      <td>3.156379e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>num__avgC</td>\n",
       "      <td>9.800435e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>num__distance_to_mobile_phone_shop</td>\n",
       "      <td>1.574106e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>num__distance_to_bank_Росбанк</td>\n",
       "      <td>1.262276e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>cat__cities_Maloyaroslavets</td>\n",
       "      <td>4.286328e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>cat__cities_Naberezhnye Chelny</td>\n",
       "      <td>1.186140e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>cat__cities_Luchegorsk</td>\n",
       "      <td>1.556823e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>cat__cities_Nizhniy Kuranakh</td>\n",
       "      <td>6.158842e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>cat__cities_Nikolayevsk-on-Amur</td>\n",
       "      <td>5.615050e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Feature    Importance\n",
       "31                           num__avgA  3.372994e-01\n",
       "0                       num__atm_group  3.156379e-01\n",
       "28                           num__avgC  9.800435e-02\n",
       "9   num__distance_to_mobile_phone_shop  1.574106e-02\n",
       "14       num__distance_to_bank_Росбанк  1.262276e-02\n",
       "..                                 ...           ...\n",
       "51         cat__cities_Maloyaroslavets  4.286328e-06\n",
       "53      cat__cities_Naberezhnye Chelny  1.186140e-06\n",
       "50              cat__cities_Luchegorsk  1.556823e-07\n",
       "57        cat__cities_Nizhniy Kuranakh  6.158842e-08\n",
       "55     cat__cities_Nikolayevsk-on-Amur  5.615050e-08\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = rff[-1]\n",
    "\n",
    "data = list(zip(clf.feature_names_in_, clf.feature_importances_))\n",
    "df_importances = pd.DataFrame(data, columns=['Feature', 'Importance']).sort_values(by='Importance', ascending=False)\n",
    "df_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d39e585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([25.26803613, 27.30754209, 26.1176405 , 24.35919476, 26.90969205]),\n",
       " 'score_time': array([1.67947388, 0.17671871, 0.95072508, 2.32744527, 0.17462707]),\n",
       " 'test_score': array([0.75758619, 0.75165409, 0.7511676 , 0.7745748 , 0.73611165]),\n",
       " 'train_score': array([0.95866012, 0.96012634, 0.95829881, 0.95772704, 0.9596965 ])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res = cross_validate(rff, X, y, cv=5, \n",
    "                        scoring='r2', n_jobs=-1, return_train_score=True, error_score='raise')\n",
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b62005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('atm_best.pkl', 'wb') as f:\n",
    "    pickle.dump(rff, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
